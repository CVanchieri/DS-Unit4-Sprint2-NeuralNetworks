{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.Assignment_NeuralNetworks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:\n",
        " - Layer of 3 input nodes that take in the outside information and pass in into the network to the hidden nodes in the hidden layer as outputs 1, X1, and X2.\n",
        "### Hidden Layer:\n",
        "- Layer of 3 hidden nodes that compute and transfer information recieved from the input nodes to the output nodes.  1 bias node with output of 1, 2 other outputs are dependent on the input layer and the weights.\n",
        "### Output Layer:\n",
        "- Layer of 2 output nodes that compute and transfer information recieved from the hidden nodes to the outside world, Y1 and Y2 are the values calculated.\n",
        "\n",
        "![feedforward neural network](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-09-at-4-19-50-am.png?w=996&h=736)\n",
        "\n",
        "### Neuron:\n",
        " - Basic unit of computation in a neural network, recieves an input and computes an output. \n",
        "### Weight:\n",
        " - Each input has a weight, size of weight is based on relative importance to the other inputs.\n",
        "\n",
        "![Single Neuron](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-09-at-3-42-21-am.png?w=1024&h=547)\n",
        "### Activation Function:\n",
        "The function f, introduces non-linearity into the output of a neuron, most real world data is not linear. Sigmmoid, Tanh, Relu are types of activation functions.\n",
        "\n",
        "![Activation Function](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-08-at-11-53-41-am.png?w=1493)\n",
        "### Node Map:\n",
        " - An overview of the layout and routes of the neural network.\n",
        "\n",
        "![Node Map](https://scikit-learn.org/stable/_images/multilayerperceptron_network.png)\n",
        "### Perceptron:\n",
        "- Perceptron has 4 parts, input values, weights and bias, netsum ,and activation function, inputs multipled by weights, weights adde together, apply weighted sum to activation function.\n",
        "\n",
        " ![Perceptron](https://miro.medium.com/max/2583/1*n6sJ4yZQzwKL9wnF5wnVNg.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Information is taken in by the input layer and then fed into the hidden layer where computation is done with weights, bias, and an activation function, the output layer recieves the informaton from the hidden layer and does more computation similar the the hidden later to get the final output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjWKhIX3O9UX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "9883fca0-e10b-4a72-913d-0c7b21ad07e3"
      },
      "source": [
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')\n",
        "df"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   1   0  1\n",
              "2   0   1  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu0p6ZoujWxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "297c619d-5fff-4ad1-9b5b-f727ac038117"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = np.array([\n",
        "                  [0, 0, 1],\n",
        "                  [1, 0, 1],\n",
        "                  [0, 1, 1],\n",
        "                  [1, 1, 1]\n",
        "])\n",
        "\n",
        "correct_outputs = [[1], [1], [1], [0]]\n",
        "print('inputs :', inputs)\n",
        "print('correct outputs :', correct_outputs)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs : [[0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 1]]\n",
            "correct outputs : [[1], [1], [1], [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI5PIlDUO9Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "be6fffa9-097a-4829-bf72-8f041ebfac51"
      },
      "source": [
        "weights = np.array([[1], [1], [-1.5]])\n",
        "weights"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1. ],\n",
              "       [ 1. ],\n",
              "       [-1.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9DMTakvk8XD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "84df1323-20e0-4b5d-d61c-97f4702faa10"
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)\n",
        "weighted_sum"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.5],\n",
              "       [-0.5],\n",
              "       [-0.5],\n",
              "       [ 0.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhHkYYQUlAH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "96294b5b-4d64-42f2-f171-5db6706bfe92"
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18242552],\n",
              "       [0.37754067],\n",
              "       [0.37754067],\n",
              "       [0.62245933]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwzxVN8mlCkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9733c9c6-be99-4f17-9ce4-5d84ea870a7f"
      },
      "source": [
        "error = correct_outputs - activated_output\n",
        "error"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.81757448],\n",
              "       [ 0.62245933],\n",
              "       [ 0.62245933],\n",
              "       [-0.62245933]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ad2mDBQlE5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d2bee3f5-bfbe-4365-b8db-22ed5094da4d"
      },
      "source": [
        "adjustments = error * sigmoid_derivative(activated_output)\n",
        "adjustments"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.2027025 ],\n",
              "       [ 0.15019874],\n",
              "       [ 0.15019874],\n",
              "       [-0.1414639 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmD7IrWvlHU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cd9fbaee-cce1-4a71-b7bf-32cf9a75f0b4"
      },
      "source": [
        "weights = weights + np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00873484],\n",
              "       [ 1.00873484],\n",
              "       [-1.13836392]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcNO9ngrl-4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ba9bb88a-00df-4bad-9f16-22d836950cc6"
      },
      "source": [
        "# Update our weights 10,000 times - (fingers crossed that this process reduces error)\n",
        "for iteration in range(10000):\n",
        "    \n",
        "    # Weighted sum of inputs / weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "    \n",
        "    # Activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "    \n",
        "    # Cac error\n",
        "    error = correct_outputs - activated_output\n",
        "    \n",
        "    adjustments = error * sigmoid_derivative(activated_output)\n",
        "    \n",
        "    # Update the Weights\n",
        "    weights += np.dot(inputs.T, adjustments)\n",
        "    \n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-11.83730984]\n",
            " [-11.83730984]\n",
            " [ 17.80483027]]\n",
            "Output after training\n",
            "[[0.99999998]\n",
            " [0.9974457 ]\n",
            " [0.9974457 ]\n",
            " [0.0028158 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLOr09DXO9Uj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "999a3281-ebd3-44b5-d8b7-ffc8074d3f2a"
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EDGg0yqO9Uo",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzCPRRwO9Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "e2060133-dad3-4c00-fd4a-0563e6adcd84"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "features = list(diabetes)[:-1]\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(diabetes[features])\n",
        "X"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg93UlJtmXgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "5d8d8b71-2c16-4d18-d4a3-54aae58790db"
      },
      "source": [
        "y = diabetes.iloc[:, 8].values\n",
        "y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePrGGq4urHRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "86c9f668-eb1b-4dcd-8f9d-a026770b5453"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label='x1')\n",
        "plt.scatter(X[50:100, 0], X[50:100, 1], color='blue', marker='x', label='x2')\n",
        "plt.xlabel('petal length')\n",
        "plt.ylabel('sepal length')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron(object):\n",
        "    \n",
        "    def __init__(self, rate = 0.01, niter = 10000):\n",
        "        self.niter = niter\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "\n",
        "        # weights\n",
        "        self.weight = np.zeros(1 + X.shape[1])\n",
        "\n",
        "        # Number of misclassifications\n",
        "        self.errors = []  # Number of misclassifications\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            err = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                predicted = self.predict(xi)\n",
        "                delta_w = self.rate * (target - predicted)\n",
        "                self.weight[1:] = self.weight[1:] + delta_w * xi\n",
        "                self.weight[0] = self.weight[0] + delta_w\n",
        "                if delta_w != 0.0:\n",
        "                    err = err + 1\n",
        "            self.errors.append(err)\n",
        "        return self\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        sx = sigmoid(x)\n",
        "        return sx * (1-sx)\n",
        "\n",
        "    def predict(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "\n",
        "        # Randomly Initialize Weights\n",
        "        self.weight = np.zeros(X.shape[1])\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            # Weighted sum of inputs / weights\n",
        "            weighted_sum = np.dot(X, self.weight)\n",
        "\n",
        "            # Activate!\n",
        "            activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "            # Calc error\n",
        "            error = y - activated_output\n",
        "            adjustments = error * sigmoid_derivative(activated_output)\n",
        "\n",
        "            # Update the Weights\n",
        "            self.weight += np.dot(X.T, adjustments)\n",
        "\n",
        "        return activated_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3DR-Riun0Dn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba6ae4bf-f21b-41fa-ef35-ebdee2c2d3d4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pn = Perceptron()\n",
        "y_pred = pn.predict(X, y)\n",
        "test = y_pred.astype(int)\n",
        "test\n",
        "accuracy_score(y, test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510416666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntZsoOVVtDv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "f7f7a0f5-71bd-453a-c2bd-98c55dda2972"
      },
      "source": [
        "pn = Perceptron(0.1, 10)\n",
        "pn.fit(X, y)\n",
        "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Number of misclassifications')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-02792181884b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of misclassifications'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-4f1628bea07c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mdelta_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'y'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYNKbom9tNNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
        "  # setup marker generator and color map\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # plot the decision surface\n",
        "    x1_min, x1_max = X[:,  0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
        "    np.arange(x2_min, x2_max, resolution))\n",
        "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    # plot class samples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
        "        alpha=0.8, c=cmap(idx),\n",
        "        marker=markers[idx], label=cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJeG1wbotUAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "f32efb09-07c1-4737-f822-4386b2804b4e"
      },
      "source": [
        "plot_decision_regions(X, y, classifier=pn)\n",
        "plt.xlabel('sepal length [cm]')\n",
        "plt.ylabel('petal length [cm]')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c90d48bbfcdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sepal length [cm]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'petal length [cm]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-f776209ef049>\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, classifier, resolution)\u001b[0m\n\u001b[1;32m     13\u001b[0m     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n\u001b[1;32m     14\u001b[0m     np.arange(x2_min, x2_max, resolution))\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'y'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}