{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.Assignment_NeuralNetworks.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dVfaLrjLvxvQ"},"source":["<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n","<br></br>\n","<br></br>\n","\n","# Neural Networks\n","\n","## *Data Science Unit 4 Sprint 2 Assignment 1*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wxtoY12mwmih"},"source":["## Define the Following:\n","You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n","\n","### Input Layer:\n"," - Layer of 3 input nodes that take in the outside information and pass in into the network to the hidden nodes in the hidden layer as outputs 1, X1, and X2.\n","### Hidden Layer:\n","- Layer of 3 hidden nodes that compute and transfer information recieved from the input nodes to the output nodes.  1 bias node with output of 1, 2 other outputs are dependent on the input layer and the weights.\n","### Output Layer:\n","- Layer of 2 output nodes that compute and transfer information recieved from the hidden nodes to the outside world, Y1 and Y2 are the values calculated.\n","\n","![feedforward neural network](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-09-at-4-19-50-am.png?w=996&h=736)\n","\n","### Neuron:\n"," - Basic unit of computation in a neural network, recieves an input and computes an output. \n","### Weight:\n"," - Each input has a weight, size of weight is based on relative importance to the other inputs.\n","\n","![Single Neuron](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-09-at-3-42-21-am.png?w=1024&h=547)\n","### Activation Function:\n","The function f, introduces non-linearity into the output of a neuron, most real world data is not linear. Sigmmoid, Tanh, Relu are types of activation functions.\n","\n","![Activation Function](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-08-at-11-53-41-am.png?w=1493)\n","### Node Map:\n"," - An overview, map,layout, routes of the neural network.\n","\n","![Node Map](https://scikit-learn.org/stable/_images/multilayerperceptron_network.png)\n","### Perceptron:\n","- Perceptron has 4 parts, input values, weights and bias, netsum ,and activation function, inputs multipled by weights, weights adde together, apply weighted sum to activation function.\n","\n"," ![Perceptron](https://miro.medium.com/max/2583/1*n6sJ4yZQzwKL9wnF5wnVNg.png)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NXuy9WcWzxa4"},"source":["## Inputs -> Outputs\n","\n","### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PlSwIJMC0A8F"},"source":["#### Information is taken in by the input layer and then fed into the hidden layer where computation is done with weights, bias, and an activation function, the output layer recieves the informaton from the hidden layer and does more computation similar the the hidden later to get the final output."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6sWR43PTwhSk"},"source":["## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n","\n","| x1 | x2 | y |\n","|----|----|---|\n","| 0  | 0  | 1 |\n","| 1  | 0  | 1 |\n","| 0  | 1  | 1 |\n","| 1  | 1  | 0 |"]},{"cell_type":"code","metadata":{"id":"UjWKhIX3O9UX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":172},"outputId":"530a9831-2c81-4b0b-a4cc-f3d608ee6ddc","executionInfo":{"status":"ok","timestamp":1580436308465,"user_tz":480,"elapsed":914,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# imports.\n","import pandas as pd\n","\n","# created data.\n","data = { 'x1': [0,1,0,1],\n","         'x2': [0,0,1,1],\n","         'y':  [1,1,1,0]\n","       }\n","# created dataframe.\n","df = pd.DataFrame.from_dict(data).astype('int')\n","df"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   x1  x2  y\n","0   0   0  1\n","1   1   0  1\n","2   0   1  1\n","3   1   1  0"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"nu0p6ZoujWxu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"af2935f0-5c51-44b1-cc3b-51271cd7dda3","executionInfo":{"status":"ok","timestamp":1580436308467,"user_tz":480,"elapsed":901,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# imports.\n","import numpy as np\n","\n","# turn data into an array.\n","inputs = np.array([\n","                  [0, 0, 1],\n","                  [1, 0, 1],\n","                  [0, 1, 1],\n","                  [1, 1, 1]\n","])\n","# set the corect outputs for y.\n","correct_outputs = [[1], [1], [1], [0]]\n","# show inputs data.\n","print('inputs :', inputs)\n","# show correct outputs data.\n","print('correct outputs :', correct_outputs)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["inputs : [[0 0 1]\n"," [1 0 1]\n"," [0 1 1]\n"," [1 1 1]]\n","correct outputs : [[1], [1], [1], [0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sgh7VFGwnXGH","colab":{}},"source":["# sigmoid activation function.\n","def sigmoid(x):\n","    return 1/ (1 + np.exp(-x))\n","# sigmoid derivative function to update weights.\n","def sigmoid_derivative(x):\n","    sx = sigmoid(x)\n","    return sx * (1-sx)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WI5PIlDUO9Ud","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"62e46849-507e-4576-8547-9723960e1095","executionInfo":{"status":"ok","timestamp":1580436308469,"user_tz":480,"elapsed":878,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# create the weights.\n","weights = np.array([[1], [1], [-1.5]])\n","# show the weights.\n","weights"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1. ],\n","       [ 1. ],\n","       [-1.5]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"D9DMTakvk8XD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"d3338aed-90f0-491d-97b4-8e05c2d6a671","executionInfo":{"status":"ok","timestamp":1580436308469,"user_tz":480,"elapsed":864,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# sum up the weights.\n","weighted_sum = np.dot(inputs, weights)\n","# show the total sum.\n","weighted_sum"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-1.5],\n","       [-0.5],\n","       [-0.5],\n","       [ 0.5]])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"dhHkYYQUlAH1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"6263e529-7217-491e-b1a3-4c6e43a6b7d5","executionInfo":{"status":"ok","timestamp":1580436308470,"user_tz":480,"elapsed":849,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# use the sigmoid function on the weighted sum.\n","activated_output = sigmoid(weighted_sum)\n","# show the output.\n","activated_output"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.18242552],\n","       [0.37754067],\n","       [0.37754067],\n","       [0.62245933]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"rwzxVN8mlCkq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"4fbeb85e-6cc2-454f-8ecf-acc971b4c0d6","executionInfo":{"status":"ok","timestamp":1580436308471,"user_tz":480,"elapsed":834,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# find the error.\n","error = correct_outputs - activated_output\n","# show the error.\n","error"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.81757448],\n","       [ 0.62245933],\n","       [ 0.62245933],\n","       [-0.62245933]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"0ad2mDBQlE5R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"55931117-4898-4677-a46f-cb82d8081cd9","executionInfo":{"status":"ok","timestamp":1580436308472,"user_tz":480,"elapsed":816,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# use the derivative function on the avivated outputs.\n","adjustments = error * sigmoid_derivative(activated_output)\n","# show the adjustments.\n","adjustments"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.2027025 ],\n","       [ 0.15019874],\n","       [ 0.15019874],\n","       [-0.1414639 ]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"DmD7IrWvlHU9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"9f0bb651-ef08-444c-d44f-bf5920825847","executionInfo":{"status":"ok","timestamp":1580436308472,"user_tz":480,"elapsed":804,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# create the new weights by adding the adjustments.\n","weights = weights + np.dot(inputs.T, adjustments)\n","weights"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.00873484],\n","       [ 1.00873484],\n","       [-1.13836392]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"pcNO9ngrl-4M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"18d82068-b39f-470b-9e7d-5797355d302c","executionInfo":{"status":"ok","timestamp":1580436308689,"user_tz":480,"elapsed":1008,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# update our weights 10,000 times - (fingers crossed that this process reduces error)\n","for iteration in range(10000):   \n","    # sum up the weights.\n","    weighted_sum = np.dot(inputs, weights)  \n","    # use the sigmoid function on the weighted sum.\n","    activated_output = sigmoid(weighted_sum)   \n","    # find the calculation error.\n","    error = correct_outputs - activated_output   \n","    # use the derivative function on the avivated outputs.\n","    adjustments = error * sigmoid_derivative(activated_output)   \n","    # Update the weights with adjustments.\n","    weights += np.dot(inputs.T, adjustments)  \n","# show weights after training.\n","print(\"Weights after training\")\n","print(weights)\n","# show output after training.\n","print(\"Output after training\")\n","print(activated_output)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Weights after training\n","[[-11.83730984]\n"," [-11.83730984]\n"," [ 17.80483027]]\n","Output after training\n","[[0.99999998]\n"," [0.9974457 ]\n"," [0.9974457 ]\n"," [0.0028158 ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xf7sdqVs0s4x"},"source":["## Implement your own Perceptron Class and use it to classify a binary dataset: \n","- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n","\n","You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."]},{"cell_type":"code","metadata":{"id":"qLOr09DXO9Uj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"cced4f27-da25-4bba-d351-54bf8d8e5949","executionInfo":{"status":"ok","timestamp":1580436309012,"user_tz":480,"elapsed":1286,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# read in the dataframe.\n","diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n","# show the dataframe with headers.\n","diabetes.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n","0            6      148             72  ...                     0.627   50        1\n","1            1       85             66  ...                     0.351   31        0\n","2            8      183             64  ...                     0.672   32        1\n","3            1       89             66  ...                     0.167   21        0\n","4            0      137             40  ...                     2.288   33        1\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"9EDGg0yqO9Uo","colab_type":"text"},"source":["Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "]},{"cell_type":"code","metadata":{"id":"SXzCPRRwO9Uq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":242},"outputId":"2e64d0f0-93ad-411b-ece8-b17e816c7b7b","executionInfo":{"status":"ok","timestamp":1580436309243,"user_tz":480,"elapsed":1493,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# imports.\n","from sklearn.preprocessing import MinMaxScaler, Normalizer\n","# set the features as an array witout the last column.\n","features = list(diabetes)[:-1]\n","# set the minmaxscalar.\n","scaler = MinMaxScaler()\n","# fit transform on the data with the set features.\n","X = scaler.fit_transform(diabetes[features])\n","# show the data.\n","X"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n","        0.48333333],\n","       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n","        0.16666667],\n","       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n","        0.18333333],\n","       ...,\n","       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n","        0.15      ],\n","       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n","        0.43333333],\n","       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n","        0.03333333]])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Fg93UlJtmXgw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624},"outputId":"f8b7ad77-709c-4df4-fefa-e49ad21c294d","executionInfo":{"status":"ok","timestamp":1580436309244,"user_tz":480,"elapsed":1475,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# set the target with the last column.\n","y = diabetes.iloc[:, 8].values\n","# show the data.\n","y"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n","       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n","       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n","       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n","       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n","       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n","       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n","       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n","       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n","       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n","       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n","       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n","       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n","       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n","       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n","       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n","       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n","       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n","       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n","       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n","       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"d1mKTBrIJfnF","colab_type":"code","colab":{}},"source":["# perceptron class.\n","class Perceptron(object):\n","    \n","    def __init__(self, niter = 10000):\n","        self.niter = niter\n","    # sigmoid activation function.\n","    def __sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","    # sigmoid derivative function to update weights.\n","    def __sigmoid_derivative(self, x):\n","        sx = sigmoid(x)\n","        return sx * (1-sx)\n","    # predict function.\n","    def predict(self, X, y):\n","        \"\"\"Fit training data\n","        X : Training vectors, X.shape : [#samples, #features]\n","        y : Target values, y.shape : [#samples]\n","        \"\"\"\n","\n","        # randomly initialize weights\n","        self.weight = np.zeros(X.shape[1])\n","\n","        for i in range(self.niter):\n","            # sum up the weights.\n","            weighted_sum = np.dot(X, self.weight)  \n","            # use the sigmoid function on the weighted sum.\n","            activated_output = sigmoid(weighted_sum)   \n","            # find the calculation error.\n","            error = y - activated_output   \n","            # use the derivative function on the avivated outputs.\n","            adjustments = error * sigmoid_derivative(activated_output)   \n","            # update the weights with adjustments.\n","            self.weight += np.dot(X.T, adjustments)\n","\n","        return activated_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3DR-Riun0Dn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":398},"outputId":"6fdc7a21-1ddc-431d-ff4e-9b0212008ebe","executionInfo":{"status":"ok","timestamp":1580437843185,"user_tz":480,"elapsed":970,"user":{"displayName":"Charles Vanchieri","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBauDRR6uSGBvI9oYit5cGU6T8SkJRV4CKiB98le2E=s64","userId":"02236610529346300368"}}},"source":["# imports.\n","from sklearn.metrics import accuracy_score\n","# set the perceptron.\n","pn = Perceptron()\n","# set the ypred with predict.\n","y_pred = pn.predict(X, y)\n","# create the test with ypred.\n","test = y_pred.astype(int)\n","print(test)\n","print('accuracy score:', accuracy_score(y, test))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","accuracy score: 0.6510416666666666\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6QR4oAW1xdyu"},"source":["## Stretch Goals:\n","\n","- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n","- Implement a multi-layer perceptron. (for non-linearly separable classes)\n","- Try and implement your own backpropagation algorithm.\n","- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"]}]}